{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###mount my Drive"
      ],
      "metadata": {
        "id": "EdPvCXaT0jz2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8PjMHJB0gRj",
        "outputId": "18869723-6b98-4fc9-bbfe-4b527eccff60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Install & Load Required Libraries"
      ],
      "metadata": {
        "id": "Onf8GVcM34ln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TniNlNnI3pzx",
        "outputId": "6d0c2a8e-a983-49e2-b106-e4b4246572fb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set Chat File Path"
      ],
      "metadata": {
        "id": "x3KTevBv3zRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_file_path = '/content/drive/MyDrive/AI_Chat_Log_Summarizer/chat.txt'\n"
      ],
      "metadata": {
        "id": "KjlFN-SK1TRL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Load Chat File"
      ],
      "metadata": {
        "id": "Bbi5j_FC1_X_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_chat(filepath):\n",
        "    with open(filepath, 'r') as file:\n",
        "        return file.readlines()\n"
      ],
      "metadata": {
        "id": "bM27oH1K14qt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Parse Chat by Speaker"
      ],
      "metadata": {
        "id": "jxu29Jug4cLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_chat(lines):\n",
        "    user_msgs, ai_msgs = [], []\n",
        "    for line in lines:\n",
        "        if line.startswith(\"User:\"):\n",
        "            user_msgs.append(line[len(\"User:\"):].strip())\n",
        "        elif line.startswith(\"AI:\"):\n",
        "            ai_msgs.append(line[len(\"AI:\"):].strip())\n",
        "    return user_msgs, ai_msgs\n"
      ],
      "metadata": {
        "id": "4ZesD-6D4Qd1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Word Frequency Function"
      ],
      "metadata": {
        "id": "MeASuojY4qqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def word_frequencies(messages):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = word_tokenize(\" \".join(messages).lower())\n",
        "    filtered_words = [w for w in words if w.isalpha() and w not in stop_words]\n",
        "    return Counter(filtered_words).most_common(5)\n"
      ],
      "metadata": {
        "id": "SPqGiCXJ4QaY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Summary Generator Function"
      ],
      "metadata": {
        "id": "kjSVl2F-49KN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize(user_msgs, ai_msgs):\n",
        "    total_msgs = len(user_msgs) + len(ai_msgs)\n",
        "    common_words = word_frequencies(user_msgs + ai_msgs)\n",
        "    keywords = ', '.join([word for word, _ in common_words])\n",
        "\n",
        "    print(\"Summary:\")\n",
        "    print(f\"- The conversation had {total_msgs} exchanges.\")\n",
        "    print(f\"- Most common keywords: {keywords}\")\n"
      ],
      "metadata": {
        "id": "IljFi2Jh4QX2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Run Everything"
      ],
      "metadata": {
        "id": "XBvWKr065ZWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lines = load_chat(chat_file_path)\n",
        "user_msgs, ai_msgs = parse_chat(lines)\n",
        "summarize(user_msgs, ai_msgs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eyXgBSr4QVJ",
        "outputId": "b319dc48-b540-4712-a622-5fbbd3932d27"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary:\n",
            "- The conversation had 4 exchanges.\n",
            "- Most common keywords: machine, learning, hello, explain, hi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "If63kHcS4QSh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}